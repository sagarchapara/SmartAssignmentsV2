{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install nltk\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key= \"28f146892bb54fd3a8ed90c8f7080f0a\",\n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint= \"https://assignments.openai.azure.com/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre process the text\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAndGenerateEmbeddings(client, fileName):\n",
    "    #read from text file\n",
    "    with open(fileName, 'r') as file:\n",
    "        data = file.read().replace('\\n', ',')\n",
    "\n",
    "    return GetEmbeddings(client, data)\n",
    "\n",
    "def GetEmbeddings(client, data):\n",
    "    # data = clean_text(data)   \n",
    "    return GenerateEmbedding(client, data)\n",
    "\n",
    "def GenerateEmbedding(client, data):\n",
    "    embedding = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input= data\n",
    "    )\n",
    "    return np.array(embedding.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartassignments\n",
    "\n",
    "villash = smartassignments.ReadAndGenerateEmbeddings(client, \"villash.txt\")\n",
    "\n",
    "print(villash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagar = ReadAndGenerateEmbeddings(client, \"sagar.txt\")\n",
    "\n",
    "abhay = ReadAndGenerateEmbeddings(client, \"abhay.txt\")\n",
    "\n",
    "# vidhu = ReadAndGenerateEmbeddings(client, \"vidhu.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleText = [\n",
    "    \"Add Accessibity tags in pdf\",\n",
    "    # \"[ATM BulkSync] Add new orchestrator for AccessSync\",\n",
    "    # \"Add Basline Api's\",\n",
    "    # \"Increase Cloudporj limits to 5000\"\n",
    "]\n",
    "\n",
    "exampleEmbedding = smartassignments.GetEmbeddings(client, exampleText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleEmbedding.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSimilarityScore(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "\n",
    "\n",
    "#print the similarity score along with name\n",
    "print(GetSimilarityScore(villash, exampleEmbedding))\n",
    "print(GetSimilarityScore(sagar, exampleEmbedding))\n",
    "# print(GetSimilarityScore(vidhu, exampleEmbedding))\n",
    "print(GetSimilarityScore(abhay, exampleEmbedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartassignments\n",
    "\n",
    "similarity_score = smartassignments.GetSimilarity(villash, exampleEmbedding)\n",
    "\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartassignments\n",
    "\n",
    "sample_message = \"\"\"const peopleList = [\n",
    "  {\n",
    "    Name: \"Abhay\",\n",
    "    workItemsList: \"1. Work Items related to UIA: These work items involve fixing crashes caused by accessing out-of-bounds columns via UIA under PageHeap. 2. Work Items related to CloudProj Rollout: These work items involve planning and executing the rollout of CloudProj, including flighting strategies and viewport support. 3. Work Items related to Memory Reduction: These work items involve investigating and reducing memory usage for task loads. 4. Work Items related to EPM: These work items involve investigating and resolving issues related to large projects, including task and resource limits. 5. Work Items related to EngSat: These work items involve fixing Visual Studio issues for CloudProj scenario tests. 6. Work Items related to Replication: These work items involve fixing issues related to dropped assignments in replication. 7. Work Items related to BulkSync: These work items involve monitoring and optimizing bulk sync operations. 8. Work Items related to Crash: These work items involve fixing crashes in CloudProj, such as those caused by creating outline codes. 9. Work Items related to Attribution: These work items involve fixing issues related to missing attribution for Project and Assignments entities. 10. Work Items related to Telemetry: These work items involve improving telemetry in CloudProj, including reducing logging pollution and correcting telemetry data. 11. Work Items related to Limits: These work items involve investigating and addressing limits related to large projects, including creating PSS work items and testing with large numbers of tasks. 12. Work Items related to Infra Setup: These work items involve setting up infrastructure for creating large projects and testing scripts. 13. Work Items related to ChinaCert: These work items involve addressing issues related to GB18030-2022 certification for Project Online and PWA settings.\"\n",
    "  },\n",
    "  {\n",
    "    Name: \"Villash\",\n",
    "    workItemsList: \"1. Work Items related to Accessibility: These work items involve adding accessibility tags to various views in Project, including Tracking Gantt, Detail Gantt, Gantt with Timeline view, Leveling Gantt view, Multiple Baselines Gantt view, Bar Rollup view, Milestone Date Rollup, Task Entry view, Resource Sheet, Task Sheet, Task Board Sheet, Sprint Planning Sheet, Current Sprint Sheet, Backlog Sheet, Network Diagram view, and Descriptive Network Diagram view. 2. Work Items related to CloudProj Stability: These work items involve investigating and fixing stability issues in CloudProj, including crashes during apply replay request for undo operation and logging for POST /project/links. 3. Work Items related to Notes Field: These work items involve fixing issues with the notes field on P4W allowing users to enter more characters than the configured maximum limit. 4. Work Items related to Alternative Text: These work items involve changing the alternative text of the diagram tag to make it more accessible for users who rely on screen readers. 5. Work Items related to Date Disparity: These work items involve investigating and fixing the date disparity between Project and Planner causing dates to shift between systems. 6. Work Items related to TaskLinks REST Endpoint: These work items involve fixing issues with the TaskLinks REST endpoint in OnPrem not returning either the PredecessorsTaskId or SuccessorsTaskId properties. 7. Work Items related to CloudProj Recalc Performance: These work items involve investigating and resolving performance issues during recalc in CloudProj. 8. Work Items related to CloudProj Recalc Telemetry: These work items involve adding helping logs in telemetry for CloudProj recalc to identify and resolve performance issues. 9. Work Items related to DST Algorithm Performance: These work items involve identifying the root cause of DST algorithm performance issues and developing a proof of concept for possible fixes. 10. Work Items related to LeadLag Feature: These work items involve enabling the LeadLag feature in CloudProj and ensuring Planner Edit converts task start and finish dates to Planner10AmDateTimeHeuristics before sending the response.\"\n",
    "  },\n",
    "  {\n",
    "    Name: \"Sagar\",\n",
    "    workItemsList: \"1. Work Items related to Exceptions: These work items involve fixing various types of exceptions that occurred during work. 2. Work Items related to Bulk Sync: These work items involve syncing data in bulk, handling conflicts and errors, and improving reliability. 3. Work Items related to Project Management: These work items involve managing projects, refreshing team assignments, and handling replication issues. 4. Work Items related to Security: These work items involve handling access changes, syncing group memberships, and triggering user impersonation. 5. Work Items related to Backfill: These work items involve backfilling data, reducing memory consumption, and improving reliability. 6. Work Items related to Testing: These work items involve enabling and disabling tests, fixing test failures, and improving telemetry. 7. Work Items related to Integration: These work items involve handling integration failures, improving integration tests, and syncing with external services. 8. Work Items related to Performance: These work items involve improving performance by reducing delay in event processing, reducing batch size, and optimizing queries. 9. Work Items related to Diagnostics: These work items involve adding diagnostic commands, cleaning up orphan plans, and verifying data. 10. Work Items related to Miscellaneous: These work items involve improving telemetry, correcting Cosmos entries, and adding new features.\"\n",
    "  }\n",
    "]\n",
    " \n",
    "Question : Please note that the work items list provided for each person may not be comprehensive and may not include all work items. Can you suggest the names of at least 1 or 2 people from the given people list who might have work items related to {taskname}? Please note that this is just a smart suggestion and may not be 100% accurate.\"\"\"\n",
    "\n",
    "some_prompt = smartassignments.GetPromptResponse(client, message = sample_message)\n",
    "\n",
    "some_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import vectordb\n",
    "import numpy as np\n",
    "\n",
    "persist_directory = \"assignment_db\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "# Create a new chroma collection\n",
    "collection_name = \"smartassignments\"\n",
    "collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "#Generate some fake data\n",
    "user_id = \"vidhu\"\n",
    "embedding = ReadAndGenerateEmbeddings(client, \"vidhu.txt\")\n",
    "\n",
    "# Store the data in the collection\n",
    "vectordb.Add(collection, user_id, embedding)\n",
    "\n",
    "# Query the collection\n",
    "query_embedding = vectordb.Get(collection, user_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding['embeddings']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
